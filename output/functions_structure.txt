MODULES MAP:

[1] anpr_detector.py - ANPR Детектор - РЕАЛЬНАЯ боевая версия для распознавания номерных знаков (30.4 KB, 726 lines)
[2] anpr_processor.py - ANPR (Automatic Number Plate Recognition) module for license plate detection and recognition. (24.7 KB, 644 lines)
[3] anpr_walker.py - ANPR Walker - Recursive image processor with unified ANPR system (41.9 KB, 1000 lines)
[4] audio_extractor.py - Audio Extractor - Вспомогательный модуль для извлечения аудио сегментов (2.7 KB, 89 lines)
[5] audio_transcriber.py - transcribe audio track from video using whisper (4.8 KB, 140 lines)
[6] chunked_video_analyzer.py - Chunked Video Analyzer - Прототип v2 (17.2 KB, 437 lines)
[7] config_manager.py - Module: unknown (6.2 KB, 161 lines)
[8] db_manager.py - PostgreSQL Database Manager for Video Tagging (17.3 KB, 513 lines)
[9] db_manager_chromadb_backup.py - ChromaDB Manager for Video Tagging (16.8 KB, 480 lines)
[10] db_manager_postgres.py - PostgreSQL Database Manager for Video Tagging (17.3 KB, 513 lines)
[11] debug_vllm.py - Debug VLLM - отладка конкретных проблемных сегментов (2.7 KB, 82 lines)
[12] face_processor.py - Face detection and clustering module using direct TensorFlow models for high performance. (22.4 KB, 607 lines)
[13] frame_extractor.py - Module: unknown (5.3 KB, 172 lines)
[14] hunyuan_translator.py - Hunyuan-MT-7B Translation Client (5.2 KB, 152 lines)
[15] load_data_to_chroma.py - Load Phase 2 VLLM analysis data into ChromaDB (6.6 KB, 202 lines)
[16] main.py - Module: unknown (16.8 KB, 434 lines)
[17] object_detector.py - Module: unknown (8.9 KB, 251 lines)
[18] pdf_generator.py - PDF Generator for ANPR Violation Reports (21.2 KB, 516 lines)
[19] performance_analyzer.py - Performance Analyzer - анализ производительности Phase 2 (10.2 KB, 222 lines)
[20] phase1_whisper_frames.py - Phase 1: Whisper Transcription + Frame Extraction (14.1 KB, 369 lines)
[21] phase2_vllm_analysis.py - Phase 2: VLLM Analysis (67.8 KB, 1357 lines)
[22] plate_detector.py - Plate Detector Module - YOLO-based detection for vehicles and license plates (9.0 KB, 261 lines)
[23] plate_recognizer.py - Plate Recognizer Module - OCR and plate structure detection (31.9 KB, 704 lines)
[24] pose_detector.py - Human pose detection and gesture analysis module using MediaPipe Pose. (18.4 KB, 471 lines)
[25] progress_monitor.py - Progress Monitor - утилита для мониторинга прогресса Phase 2 (2.6 KB, 69 lines)
[26] result_exporter.py - Module: unknown (3.5 KB, 94 lines)
[27] run_vllm_analysis.py - VLLM Video Analysis Module - Отдельный модуль для анализа видео через Vision-Language модель (6.7 KB, 188 lines)
[28] scene_analyzer.py - Module: unknown (14.6 KB, 352 lines)
[29] test_search.py - Test ChromaDB search functionality (3.8 KB, 135 lines)
[30] translator.py - Translation module using local LLM via text-generation-webui API. (10.7 KB, 321 lines)
[31] unified_anpr_system.py - Unified ANPR System - Main orchestrator module (31.8 KB, 765 lines)
[32] vehicle_compcars_analyzer.py - CompCars-based vehicle analysis module for detailed make/model classification. (19.5 KB, 481 lines)
[33] vehicle_yolo_detector.py - YOLO-based vehicle detection module for video processing pipeline. (13.6 KB, 360 lines)
[34] video_transcriber.py - Video Transcription Module - Отдельный модуль для транскрипции видео через Whisper (10.1 KB, 292 lines)
[35] vllm_client.py - VLLM Client for video frame analysis using Qwen 2.5 VL model (10.9 KB, 276 lines)
[36] vllm_scene_director.py - VLLM Scene Director - "Режиссер" для умной нарезки видео на сцены (22.3 KB, 516 lines)

FUNCTION CALL STRUCTURE:

Entry Point: [2] anpr_processor.py
[2] main()
  └─ [2] initialize_anpr_models()
  └─ [2] process_single_video_anpr()

Entry Point: [3] anpr_walker.py
[3] main()
  └─ [3] run()

Entry Point: [6] chunked_video_analyzer.py
[6] main()
  └─ [6] initialize_models()
  └─ [6] process_video()
  └─ [6] export_results()
  └─ [4] cleanup_temp_files()

Entry Point: [8] db_manager.py
[8] encode()
[8] create_or_update_video_file()
  └─ [8] _ensure_connection()
[8] get_video_status()
  └─ [8] _ensure_connection()
[8] update_video_status()
  └─ [8] _ensure_connection()
[8] list_videos()
  └─ [8] _ensure_connection()
[8] add_segments()
  └─ [8] _ensure_connection()
[8] search()
  └─ [8] _ensure_connection()
[8] get_collection_stats()
  └─ [8] _ensure_connection()
[8] delete_video_segments()
  └─ [8] _ensure_connection()
[8] close()

Entry Point: [9] db_manager_chromadb_backup.py
[9] add_segments()
[9] search()
[9] get_collection_stats()
[9] delete_video_segments()
[9] reset_collections()
[9] create_or_update_video_file()
[9] get_video_status()
[9] update_video_status()
  └─ [8] get_video_status()
[9] list_videos()

Entry Point: [10] db_manager_postgres.py
[10] encode()
[10] create_or_update_video_file()
  └─ [8] _ensure_connection()
[10] get_video_status()
  └─ [8] _ensure_connection()
[10] update_video_status()
  └─ [8] _ensure_connection()
[10] list_videos()
  └─ [8] _ensure_connection()
[10] add_segments()
  └─ [8] _ensure_connection()
[10] search()
  └─ [8] _ensure_connection()
[10] get_collection_stats()
  └─ [8] _ensure_connection()
[10] delete_video_segments()
  └─ [8] _ensure_connection()
[10] close()

Entry Point: [11] debug_vllm.py
[11] debug_segment()

Entry Point: [14] hunyuan_translator.py
[14] test_hunyuan_translator()
  └─ [14] test_connection()
  └─ [14] translate_to_russian()

Entry Point: [15] load_data_to_chroma.py
[15] main()
  └─ [15] load_video_to_chroma()

Entry Point: [16] main.py
[16] main()
  └─ [6] load_config()
  └─ [16] setup_output_directories()
  └─ [28] initialize_clip_model()
  └─ [17] initialize_yolo_model()
  └─ [16] process_single_video()

Entry Point: [19] performance_analyzer.py
[19] main()
  └─ [19] generate_report()

Entry Point: [20] phase1_whisper_frames.py
[20] main()
  └─ [20] load_videos_config()
  └─ [20] initialize_whisper()
  └─ [20] process_video_phase1()

Entry Point: [21] phase2_vllm_analysis.py
[21] main()
  └─ [21] test_model_control()
  └─ [21] process_phase2_analysis()

Entry Point: [24] pose_detector.py
[24] main()
  └─ [24] initialize_pose_model()
  └─ [24] process_single_video_poses()

Entry Point: [25] progress_monitor.py
[25] monitor_progress()

Entry Point: [27] run_vllm_analysis.py
[27] main()
  └─ [27] process_single_video_vllm()

Entry Point: [29] test_search.py
[29] main()
  └─ [29] print_result()
  └─ [29] format_time() (×2)

Entry Point: [31] unified_anpr_system.py
[31] main()
  └─ [31] analyze_frame()
  └─ [6] process_video()

Entry Point: [32] vehicle_compcars_analyzer.py
[32] main()
  └─ [32] initialize_compcars_models()
  └─ [32] process_single_video_compcars()

Entry Point: [33] vehicle_yolo_detector.py
[33] main()
  └─ [33] initialize_yolo_vehicle_model()
  └─ [33] process_single_video_yolo_vehicles()

Entry Point: [34] video_transcriber.py
[34] main()
  └─ [34] process_single_video_transcription()

Entry Point: [35] vllm_client.py
[35] analyze_video_frames_vllm()
  └─ [14] test_connection()
  └─ [35] prepare_context_for_frame()
  └─ [31] analyze_frame()
[35] prepare_context_for_frame()

Entry Point: [36] vllm_scene_director.py
[36] main()
  └─ [36] process_video_segmentation()
  └─ [36] export_segmentation_results()

Module: [1] anpr_detector.py
[1] __init__()
  └─ [1] _load_models()
[1] _analyze_car_brand()
  └─ [1] _extract_text_regions()
[1] _analyze_for_violations()
[1] _check_gpu_available()
[1] _classify_car_type()
[1] _detect_car_color()
[1] _detect_traffic_light_violations()
[1] _detect_vehicles()
  └─ [1] _get_vehicle_class_name()
[1] _extract_text_regions()
[1] _get_plate_format()
[1] _get_plate_type()
[1] _get_region_from_plate()
[1] _get_vehicle_class_name()
[1] _load_models()
  └─ [1] _check_gpu_available()
[1] _preprocess_image()
[1] _validate_license_plate()
  └─ [1] _get_region_from_plate()
  └─ [1] _get_plate_type()
  └─ [1] _get_plate_format()
[1] analyze_image()
  └─ [1] _check_gpu_available()
  └─ [1] detect_license_plates()
  └─ [1] detect_violations()
  └─ [1] detect_streets()
  └─ [1] detect_car_brands()
[1] detect_car_brands()
  └─ [1] _detect_vehicles()
  └─ [1] _analyze_car_brand()
  └─ [1] _detect_car_color() (×2)
  └─ [1] _classify_car_type() (×2)
[1] detect_license_plates()
  └─ [1] _preprocess_image()
  └─ [1] _detect_vehicles()
  └─ [1] _extract_text_regions()
  └─ [1] _validate_license_plate()
[1] detect_streets()
  └─ [1] _preprocess_image()
  └─ [1] _extract_text_regions()
[1] detect_violations()
  └─ [1] _analyze_for_violations()
  └─ [1] _detect_traffic_light_violations()

Entry Point Module: [2] anpr_processor.py
[2] convert_cyrillic_to_latin()
[2] detect_license_plates_batch()
  └─ [7] get_processing_params()
  └─ [2] process_frame_anpr()
  └─ [2] group_plates_by_timestamp()
[2] enhance_plate_image()
[2] export_anpr_results()
  └─ [26] create_output_filename()
  └─ [26] export_objects_csv()
[2] extract_plate_regions()
[2] get_kazakhstan_regions()
[2] get_license_plate_patterns()
  └─ [2] get_kazakhstan_regions() (×2)
  └─ [2] get_russia_regions() (×3)
[2] get_russia_regions()
[2] group_plates_by_timestamp()
[2] initialize_anpr_models()
  └─ [2] get_license_plate_patterns()
[2] main()
  └─ [2] initialize_anpr_models()
  └─ [2] process_single_video_anpr()
[2] process_frame_anpr()
  └─ [2] extract_plate_regions()
  └─ [2] recognize_plate_text()
  └─ [2] validate_license_plate()
[2] process_single_video_anpr()
  └─ [7] set_video_path()
  └─ [7] get_processing_params()
  └─ [13] extract_frames_with_timestamps()
  └─ [2] detect_license_plates_batch()
  └─ [2] export_anpr_results()
[2] recognize_plate_text()
  └─ [2] enhance_plate_image()
[2] validate_license_plate()
  └─ [2] convert_cyrillic_to_latin()

Entry Point Module: [3] anpr_walker.py
[3] main()
  └─ [3] run()
[3] __init__()
  └─ [3] _setup_logging()
[3] _finalize_stats()
[3] _group_violation_sequences()
  └─ [3] _parse_timestamp_from_filename() (×2)
[3] _parse_timestamp_from_filename()
[3] _safe_imread()
[3] _select_best_frame_from_group()
  └─ [3] get_metadata_path()
[3] _setup_logging()
[3] find_images()
[3] get_metadata_path()
[3] process_image()
  └─ [3] _safe_imread()
[3] run()
  └─ [3] find_images()
  └─ [3] _finalize_stats() (×2)
  └─ [3] _group_violation_sequences()
  └─ [3] should_process()
  └─ [3] get_metadata_path()
  └─ [3] process_image()
  └─ [3] save_metadata()
  └─ [3] _select_best_frame_from_group()
  └─ [3] _safe_imread()
[3] save_metadata()
  └─ [3] get_metadata_path()
[3] should_process()
  └─ [3] get_metadata_path()

Module: [4] audio_extractor.py
[4] check_ffmpeg_available()
[4] cleanup_temp_files()
[4] extract_audio_segment()

Module: [5] audio_transcriber.py
[5] extract_audio_from_video()
[5] format_timestamp()
[5] initialize_whisper_model()
[5] process_transcription_segments()
  └─ [5] format_timestamp() (×4)
[5] transcribe_audio()
[5] transcribe_video_file()
  └─ [7] get_processing_params()
  └─ [7] get_video_path()
  └─ [7] get_audio_dir()
  └─ [5] extract_audio_from_video()
  └─ [5] initialize_whisper_model()
  └─ [5] transcribe_audio()
  └─ [5] process_transcription_segments()

Entry Point Module: [6] chunked_video_analyzer.py
[6] main()
  └─ [6] initialize_models()
  └─ [6] process_video()
  └─ [6] export_results()
  └─ [4] cleanup_temp_files()
[6] __init__()
  └─ [6] load_config()
[6] analyze_segment()
  └─ [API] POST (dynamic URL)
[6] calculate_frame_resolution()
[6] create_vllm_prompt()
[6] export_results()
[6] extract_segment_frames()
[6] get_video_info()
[6] initialize_models()
  └─ [4] check_ffmpeg_available()
[6] load_config()
[6] process_video()
  └─ [7] set_video_path()
  └─ [6] get_video_info()
  └─ [6] calculate_frame_resolution()
  └─ [6] extract_segment_frames()
  └─ [6] transcribe_segment()
  └─ [6] create_vllm_prompt()
  └─ [6] analyze_segment()
[6] transcribe_segment()
  └─ [4] extract_audio_segment()

Module: [7] config_manager.py
[7] get_audio_dir()
[7] get_output_dir()
[7] get_processing_params()
[7] get_video_info()
  └─ [7] get_video_path()
[7] get_video_path()
[7] load_config()
[7] set_video_path()

Entry Point Module: [8] db_manager.py
[8] __new__()
[8] encode()
[8] __del__()
  └─ [8] close()
[8] __init__()
  └─ [8] _get_connection()
[8] _ensure_connection()
  └─ [8] _get_connection()
[8] _get_connection()
[8] add_segments()
  └─ [8] _ensure_connection()
[8] close()
[8] create_or_update_video_file()
  └─ [8] _ensure_connection()
[8] delete_video_segments()
  └─ [8] _ensure_connection()
[8] get_collection_stats()
  └─ [8] _ensure_connection()
[8] get_video_status()
  └─ [8] _ensure_connection()
[8] list_videos()
  └─ [8] _ensure_connection()
[8] search()
  └─ [8] _ensure_connection()
[8] update_video_status()
  └─ [8] _ensure_connection()

Entry Point Module: [9] db_manager_chromadb_backup.py
[9] __init__()
[9] add_segments()
[9] create_or_update_video_file()
[9] delete_video_segments()
[9] get_collection_stats()
[9] get_video_status()
[9] list_videos()
[9] reset_collections()
[9] search()
[9] update_video_status()
  └─ [8] get_video_status()

Entry Point Module: [10] db_manager_postgres.py
[10] __new__()
[10] encode()
[10] __del__()
  └─ [8] close()
[10] __init__()
  └─ [8] _get_connection()
[10] _ensure_connection()
  └─ [8] _get_connection()
[10] _get_connection()
[10] add_segments()
  └─ [8] _ensure_connection()
[10] close()
[10] create_or_update_video_file()
  └─ [8] _ensure_connection()
[10] delete_video_segments()
  └─ [8] _ensure_connection()
[10] get_collection_stats()
  └─ [8] _ensure_connection()
[10] get_video_status()
  └─ [8] _ensure_connection()
[10] list_videos()
  └─ [8] _ensure_connection()
[10] search()
  └─ [8] _ensure_connection()
[10] update_video_status()
  └─ [8] _ensure_connection()

Entry Point Module: [11] debug_vllm.py
[11] debug_segment()

Module: [12] face_processor.py
[12] cluster_faces_to_persons()
  └─ [12] is_same_person()
[12] detect_faces()
  └─ [12] detect_faces_single_frame()
[12] detect_faces_batch()
  └─ [7] get_processing_params()
  └─ [12] initialize_face_models()
  └─ [12] detect_faces_single_frame()
  └─ [12] process_faces_batch_tf()
  └─ [12] cluster_faces_to_persons()
  └─ [12] group_faces_by_timestamp()
[12] detect_faces_single_frame()
[12] group_faces_by_timestamp()
[12] initialize_face_models()
[12] is_same_person()
[12] preprocess_face_for_tf()
[12] process_faces_batch_tf()
  └─ [12] process_faces_with_deepface()
  └─ [12] process_faces_with_tf_models()
[12] process_faces_with_deepface()
[12] process_faces_with_tf_models()
  └─ [12] preprocess_face_for_tf()

Module: [13] frame_extractor.py
[13] extract_frames()
[13] extract_frames_with_timestamps()
  └─ [13] seconds_to_timestamp()
[13] frames_to_timestamps()
  └─ [13] seconds_to_timestamp()
[13] get_video_info()
[13] process_video_frames()
  └─ [7] get_video_path()
  └─ [13] extract_frames()
  └─ [6] get_video_info()
  └─ [13] frames_to_timestamps()
[13] seconds_to_timestamp()

Entry Point Module: [14] hunyuan_translator.py
[14] test_hunyuan_translator()
  └─ [14] test_connection()
  └─ [14] translate_to_russian()
[14] __init__()
[14] test_connection()
[14] translate()
[14] translate_chinese_to_russian()
  └─ [14] translate()
[14] translate_english_to_russian()
  └─ [14] translate()
[14] translate_to_russian()
  └─ [14] translate()

Entry Point Module: [15] load_data_to_chroma.py
[15] load_phase2_json()
[15] load_video_to_chroma()
  └─ [15] load_phase2_json()
[15] main()
  └─ [15] load_video_to_chroma()

Entry Point Module: [16] main.py
[16] export_face_results()
  └─ [7] get_video_path()
  └─ [26] create_output_filename() (×2)
  └─ [26] export_faces_csv()
  └─ [26] export_face_timeline_csv()
[16] export_object_results()
  └─ [7] get_video_path()
  └─ [26] create_output_filename()
  └─ [26] export_objects_csv()
[16] export_scene_results()
  └─ [7] get_video_path()
  └─ [26] create_output_filename()
  └─ [26] export_scenes_csv()
[16] export_transcription_results()
  └─ [7] get_video_path()
  └─ [26] create_output_filename()
  └─ [26] export_transcription_csv()
[16] export_translated_transcription_results()
  └─ [7] get_video_path()
  └─ [26] create_output_filename()
  └─ [26] export_transcription_csv()
[16] extract_video_frames()
  └─ [6] load_config()
  └─ [7] get_video_path()
  └─ [13] extract_frames_with_timestamps()
[16] main()
  └─ [6] load_config()
  └─ [16] setup_output_directories()
  └─ [28] initialize_clip_model()
  └─ [17] initialize_yolo_model()
  └─ [16] process_single_video()
[16] process_audio_transcription()
  └─ [5] transcribe_video_file()
[16] process_single_video()
  └─ [7] set_video_path()
  └─ [16] extract_video_frames()
  └─ [16] process_video_scenes()
  └─ [16] export_scene_results()
  └─ [16] process_video_objects()
  └─ [16] export_object_results()
  └─ [16] process_video_faces()
  └─ [16] export_face_results()
  └─ [16] process_audio_transcription()
  └─ [16] export_transcription_results()
  └─ [...] 3 more calls
[16] process_translation()
[16] process_video_faces()
  └─ [12] detect_faces_batch()
[16] process_video_objects()
  └─ [6] load_config()
  └─ [17] detect_objects_batch()
[16] process_video_scenes()
  └─ [6] load_config()
  └─ [28] detect_scene_changes()
[16] setup_output_directories()
  └─ [7] get_output_dir()

Module: [17] object_detector.py
[17] detect_objects()
  └─ [17] process_yolo_results_single()
[17] detect_objects_batch()
  └─ [7] get_processing_params()
  └─ [17] process_yolo_results_single()
  └─ [17] group_objects_by_timestamp()
[17] get_object_center()
[17] group_objects_by_timestamp()
[17] initialize_yolo_model()
[17] process_yolo_results_single()
  └─ [17] get_object_center()

Module: [18] pdf_generator.py
[18] __init__()
  └─ [18] _register_fonts()
  └─ [18] _load_logo_as_base64()
[18] _create_footer()
[18] _create_header()
[18] _cv2_to_reportlab_image()
[18] _extract_plate_image()
[18] _load_logo_as_base64()
[18] _register_fonts()
[18] create_violation_report()
  └─ [18] _extract_plate_image()
  └─ [18] _cv2_to_reportlab_image() (×2)
[18] should_generate_pdf()

Entry Point Module: [19] performance_analyzer.py
[19] main()
  └─ [19] generate_report()
[19] __init__()
[19] analyze_json_quality()
[19] analyze_processing_time()
  └─ [19] extract_timestamp() (×3)
  └─ [19] extract_segment_number()
[19] calculate_metrics()
[19] extract_segment_number()
[19] extract_timestamp()
[19] generate_report()
  └─ [19] load_results()
  └─ [19] calculate_metrics()
  └─ [19] analyze_json_quality()
[19] load_results()

Entry Point Module: [20] phase1_whisper_frames.py
[20] load_videos_config()
[20] main()
  └─ [20] load_videos_config()
  └─ [20] initialize_whisper()
  └─ [20] process_video_phase1()
[20] __init__()
[20] calculate_frame_resolution()
[20] create_segments()
[20] extract_segment_frames()
[20] get_video_info()
[20] initialize_whisper()
  └─ [4] check_ffmpeg_available()
[20] process_video_phase1()
  └─ [6] get_video_info()
  └─ [6] calculate_frame_resolution()
  └─ [20] create_segments()
  └─ [7] set_video_path()
  └─ [6] extract_segment_frames()
  └─ [6] transcribe_segment()
  └─ [20] save_phase1_results()
  └─ [4] cleanup_temp_files()
[20] save_phase1_results()
[20] transcribe_segment()
  └─ [4] extract_audio_segment()

Entry Point Module: [21] phase2_vllm_analysis.py
[21] main()
  └─ [21] test_model_control()
  └─ [21] process_phase2_analysis()
[21] test_model_control()
  └─ [21] get_model_status() (×2)
  └─ [21] stop_model()
  └─ [21] wait_for_model_stop()
  └─ [21] start_model()
  └─ [21] wait_for_model_restart()
  └─ [21] test_vllm_connection()
[21] tqdm()
[21] __init__()
  └─ [6] load_config()
[21] _convert_markdown_to_json()
[21] _extract_from_markdown_blocks()
[21] _is_structured_markdown()
[21] analyze_segment_vllm()
[21] auto_start_model_if_needed()
  └─ [21] start_model()
  └─ [21] test_vllm_connection()
[21] check_model_health()
  └─ [21] test_vllm_connection()
[21] check_preventive_restart()
[21] create_vllm_prompt()
[21] detect_quality_degradation()
[21] extract_json_from_response()
  └─ [21] _extract_from_markdown_blocks()
  └─ [21] _is_structured_markdown()
  └─ [21] _convert_markdown_to_json()
[21] get_base64_frames()
  └─ [21] tqdm()
[21] get_flag_path()
[21] get_model_status()
  └─ [21] read_status_file()
[21] get_previous_segment_context()
  └─ [21] load_existing_results()
[21] get_segments_to_process()
  └─ [21] load_existing_results()
[21] load_config()
[21] load_existing_results()
[21] load_phase1_data()
[21] merge_results()
  └─ [21] load_existing_results()
  └─ [21] load_phase1_data()
[21] process_phase2_analysis()
  └─ [21] test_vllm_connection() (×2)
  └─ [21] auto_start_model_if_needed()
  └─ [21] load_phase1_data()
  └─ [21] get_segments_to_process()
  └─ [21] tqdm()
  └─ [21] check_preventive_restart()
  └─ [21] restart_model() (×3)
  └─ [21] check_model_health()
  └─ [21] get_base64_frames()
  └─ [21] get_previous_segment_context()
  └─ [...] 6 more calls
[21] read_status_file()
  └─ [21] get_flag_path()
[21] request_model_restart()
  └─ [21] restart_model()
[21] restart_model()
  └─ [21] write_flag_file()
[21] save_phase2_results()
  └─ [21] merge_results()
[21] start_model()
  └─ [21] write_flag_file()
[21] stop_model()
  └─ [21] write_flag_file()
[21] test_vllm_connection()
[21] wait_for_model_restart()
  └─ [21] get_flag_path()
  └─ [21] test_vllm_connection()
[21] wait_for_model_stop()
  └─ [21] get_model_status()
[21] write_flag_file()
  └─ [21] get_flag_path()

Module: [22] plate_detector.py
[22] __init__()
  └─ [22] _get_default_config()
  └─ [22] _init_models()
[22] _get_default_config()
[22] _init_models()
[22] detect_plates()
[22] detect_vehicles()
[22] extract_plate_zones_from_vehicle()
[22] extract_region()
[22] select_primary_vehicle()

Module: [23] plate_recognizer.py
[23] fix_kg_text()
[23] is_above()
[23] __init__()
  └─ [23] _load_plate_patterns()
[23] _detect_plate_structure()
  └─ [23] fix_kg_text() (×9)
  └─ [23] is_above() (×6)
[23] _load_plate_patterns()
[23] _safe_extract_ocr_results()
[23] recognize()
  └─ [23] _safe_extract_ocr_results()
  └─ [23] _detect_plate_structure()

Entry Point Module: [24] pose_detector.py
[24] analyze_gesture()
[24] calculate_pose_bbox()
[24] detect_poses_batch()
  └─ [7] get_processing_params()
  └─ [24] process_single_frame_pose()
  └─ [24] group_poses_by_timestamp()
[24] export_pose_results()
  └─ [26] create_output_filename()
  └─ [26] export_objects_csv()
[24] extract_pose_metrics()
[24] group_poses_by_timestamp()
[24] initialize_pose_model()
[24] main()
  └─ [24] initialize_pose_model()
  └─ [24] process_single_video_poses()
[24] process_single_frame_pose()
  └─ [24] analyze_gesture()
  └─ [24] calculate_pose_bbox()
  └─ [24] extract_pose_metrics()
[24] process_single_video_poses()
  └─ [7] set_video_path()
  └─ [7] get_processing_params()
  └─ [13] extract_frames_with_timestamps()
  └─ [24] detect_poses_batch()
  └─ [24] export_pose_results()

Entry Point Module: [25] progress_monitor.py
[25] monitor_progress()

Module: [26] result_exporter.py
[26] create_output_filename()
  └─ [7] get_output_dir()
[26] export_face_timeline_csv()
[26] export_faces_csv()
[26] export_objects_csv()
[26] export_scenes_csv()
[26] export_transcription_csv()

Entry Point Module: [27] run_vllm_analysis.py
[27] export_vllm_results()
  └─ [26] create_output_filename()
  └─ [26] export_objects_csv()
[27] load_context_from_other_modules()
[27] main()
  └─ [27] process_single_video_vllm()
[27] process_single_video_vllm()
  └─ [7] set_video_path()
  └─ [13] extract_frames_with_timestamps()
  └─ [27] load_context_from_other_modules()
  └─ [35] analyze_video_frames_vllm()
  └─ [27] export_vllm_results()

Module: [28] scene_analyzer.py
[28] analyze_scene()
  └─ [28] get_scene_description()
[28] detect_scene_changes()
  └─ [28] initialize_clip_model()
  └─ [7] get_processing_params()
  └─ [28] get_scene_description()
[28] get_fallback_scene_description()
[28] get_scene_description()
  └─ [28] simplify_scene_name()
  └─ [28] get_fallback_scene_description()
[28] initialize_clip_model()
[28] simplify_scene_name()

Entry Point Module: [29] test_search.py
[29] format_time()
[29] main()
  └─ [29] print_result()
  └─ [29] format_time() (×2)
[29] print_result()
  └─ [29] format_time() (×2)

Module: [30] translator.py
[30] call_llm_api()
  └─ [API] POST (dynamic URL)
[30] group_segments_into_chunks()
[30] parse_translated_line()
[30] parse_translated_response()
  └─ [30] parse_translated_line()
[30] save_translation_debug_info()
[30] translate_chunk()
  └─ [30] call_llm_api()
  └─ [30] parse_translated_response()
[30] translate_transcription_segments()
  └─ [7] get_processing_params()
  └─ [30] group_segments_into_chunks()
  └─ [30] translate_chunk()

Entry Point Module: [31] unified_anpr_system.py
[31] main()
  └─ [31] analyze_frame()
  └─ [6] process_video()
[31] __init__()
  └─ [22] _get_default_config()
  └─ [3] _setup_logging()
[31] _enhance_plate_image()
[31] _extract_radar_data()
[31] _generate_summary()
[31] _get_default_config()
[31] _ocr_pass_fullscreen()
[31] _ocr_pass_plate_zones()
  └─ [31] _enhance_plate_image()
[31] _ocr_pass_vehicle_zones()
[31] _process_yolo_plates()
  └─ [31] _enhance_plate_image()
[31] _setup_logging()
[31] analyze_frame()
  └─ [31] _extract_radar_data()
  └─ [31] _process_yolo_plates()
  └─ [31] _ocr_pass_fullscreen()
  └─ [31] _ocr_pass_vehicle_zones()
  └─ [31] _ocr_pass_plate_zones()
  └─ [31] to_dict() (×2)
[31] process_video()
  └─ [31] analyze_frame()
  └─ [31] _generate_summary()
[31] to_dict()

Entry Point Module: [32] vehicle_compcars_analyzer.py
[32] analyze_vehicles_batch()
  └─ [32] get_compcars_class_names()
  └─ [7] get_processing_params()
  └─ [32] process_frame_vehicles()
  └─ [32] group_vehicle_analysis_by_timestamp()
[32] classify_vehicle_region()
[32] create_compcars_classifier()
[32] create_compcars_transform()
[32] export_vehicle_analysis_results()
  └─ [26] create_output_filename()
  └─ [26] export_objects_csv()
[32] get_compcars_class_names()
[32] group_vehicle_analysis_by_timestamp()
[32] initialize_compcars_models()
  └─ [32] create_compcars_classifier()
  └─ [32] create_compcars_transform()
[32] main()
  └─ [32] initialize_compcars_models()
  └─ [32] process_single_video_compcars()
[32] process_frame_vehicles()
  └─ [32] classify_vehicle_region()
[32] process_single_video_compcars()
  └─ [7] set_video_path()
  └─ [7] get_processing_params()
  └─ [13] extract_frames_with_timestamps()
  └─ [32] analyze_vehicles_batch()
  └─ [32] export_vehicle_analysis_results()

Entry Point Module: [33] vehicle_yolo_detector.py
[33] detect_vehicles_batch()
  └─ [7] get_processing_params()
  └─ [33] process_yolo_vehicle_results()
  └─ [33] group_vehicles_by_timestamp()
[33] export_vehicle_results()
  └─ [26] create_output_filename()
  └─ [26] export_objects_csv()
[33] get_vehicle_center()
[33] group_vehicles_by_timestamp()
[33] initialize_yolo_vehicle_model()
[33] main()
  └─ [33] initialize_yolo_vehicle_model()
  └─ [33] process_single_video_yolo_vehicles()
[33] process_single_video_yolo_vehicles()
  └─ [7] set_video_path()
  └─ [7] get_processing_params()
  └─ [13] extract_frames_with_timestamps()
  └─ [33] detect_vehicles_batch()
  └─ [33] export_vehicle_results()
[33] process_yolo_vehicle_results()
  └─ [33] get_vehicle_center()

Entry Point Module: [34] video_transcriber.py
[34] clean_repetitive_segments()
[34] export_transcription_results()
  └─ [26] create_output_filename()
  └─ [26] export_transcription_csv()
[34] format_timestamp()
[34] initialize_whisper_model()
[34] main()
  └─ [34] process_single_video_transcription()
[34] process_single_video_transcription()
  └─ [7] set_video_path()
  └─ [5] initialize_whisper_model()
  └─ [5] transcribe_video_file()
  └─ [16] export_transcription_results()
[34] process_transcription_segments()
  └─ [5] format_timestamp() (×2)
[34] transcribe_video_file()
  └─ [5] process_transcription_segments()

Entry Point Module: [35] vllm_client.py
[35] analyze_video_frames_vllm()
  └─ [14] test_connection()
  └─ [35] prepare_context_for_frame()
  └─ [31] analyze_frame()
[35] prepare_context_for_frame()
[35] __init__()
  └─ [6] load_config()
[35] analyze_frame()
  └─ [35] frame_to_base64()
[35] frame_to_base64()
  └─ [35] resize_frame_if_needed()
[35] load_config()
[35] resize_frame_if_needed()
[35] test_connection()

Entry Point Module: [36] vllm_scene_director.py
[36] export_segmentation_results()
[36] main()
  └─ [36] process_video_segmentation()
  └─ [36] export_segmentation_results()
[36] __init__()
[36] analyze_multiple_frames_vllm()
  └─ [API] POST (dynamic URL)
[36] analyze_segment_with_vllm()
  └─ [36] analyze_multiple_frames_vllm()
[36] create_video_segments()
[36] extract_mini_frames()
  └─ [13] extract_frames_with_timestamps()
[36] load_transcription_segments()
[36] process_video_segmentation()
  └─ [7] set_video_path()
  └─ [36] load_transcription_segments()
  └─ [36] create_video_segments()
  └─ [36] extract_mini_frames()
  └─ [36] analyze_segment_with_vllm()
